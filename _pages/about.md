---
layout: about
title: About Me
permalink: /
subtitle: Mechanistic Interpretability Researcher | Trustworthy AI Proponent | Master's Student at <a href='https://en.sharif.edu/'>Sharif University of Technology</a>.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: true # crops the image to make it circular
  more_info: >
    <p>Speech and Language Processing Lab (SLPL)</p>
    <p>Sharif University of Technology</p>
    <p>Tehran, Iran</p>

news: false # includes a list of news items
latest_posts: false # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

### Hello! I'm Hamidreza ðŸ˜Š

I am a Master's student in the [Computer Engineering Department](https://ce.sharif.edu/) at [Sharif University of Technology (SUT)](https://en.sharif.edu/), where I am dedicated to enhancing AI safety through mechanistic interpretability. My research focuses on improving the transparency and interpretability of transformer language models, supporting the broader objective of achieving AI alignment.

As a Research Assistant at the [Speech and Language Processing Lab](https://www.sharif.edu/web/slpl_ce) under the supervision of [Prof. Sameti](https://scholar.google.com/citations?user=ebEhWZwAAAAJ&hl=en&oi=ao), I am broadly interested in AI, Machine Learning, and Natural Language Processing (NLP). I am particularly focused on model interpretability and the development of trustworthy AI systems.

Prior to joining SUT, I completed my Bachelor's degree in Mechanical Engineering at [Tehran Polytechnic (AUT)](https://aut.ac.ir/en). During my undergraduate studies, I served as a Research Assistant in the New Technologies and Robotics Lab under the guidance of [Dr. Zareinejad](https://scholar.google.com/citations?user=xx8zwXYAAAAJ&hl=en&oi=ao).

I am passionate about advancing the field of AI by making models more interpretable, transparent, and trustworthy, ultimately contributing to a safer and more aligned AI future.

### Research Focus
In the early stages of my mechanistic interpretability research, I began my journey by concentrating on the following areas:

- Investigating how different LMs utilize multiple cue words to predict grammatical tasks, employing [context mixing](https://arxiv.org/abs/2301.12971) techniques to examine the internal representations, and using [activation patching](https://arxiv.org/abs/2202.05262) to establish a causal link between these representations and the model's predictions.
- Implementing [Sparse Autoencoders](http://arxiv.org/abs/2309.08600) to conquer the [Superposition](https://transformer-circuits.pub/2023/superposition-composition/index.html.), i.e. finding the redemption in Neural nets interpretability!
- Aiming to extract reasoning circuits within a zero-shot or chain-of-thought reasoning process of a large language model (LLM).
